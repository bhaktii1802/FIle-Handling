# -*- coding: utf-8 -*-
"""File_Handling_task.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1A3cZ6nmDTXUN5IPZbEWeMasFlaR3jrft
"""

import csv
import shutil

f = open('googl_daily_prices.csv', 'r')
f.read()

with open('googl_daily_prices.csv', 'r' ) as file:
    google_data = csv.DictReader(file, delimiter = ',')
    #print(google_data)
    for rec in google_data:
        print(rec)

print("Filename:", f.name)

print("Mode:", f.mode)

print("Is Closed?", f.closed)

f.close()
print("Is Closed?", f.closed)

file = open("googl_daily_prices.csv", "r")
content = file.read()
print(content)
file.close()

try:
    file = open("googl_daily_prices.csv", "r")
    content = file.read()
    print(content)
finally:
    file.close()

CSV_PATH = 'googl_daily_prices.csv'
BACKUP_PATH = CSV_PATH + '.bak'

shutil.copy2(CSV_PATH, BACKUP_PATH)
print(f"Backup created at {BACKUP_PATH}")

def clean_name(h):
    h = h.strip().lower()
    # remove leading non-alphanumeric chars and digits
    while h and (not h[0].isalnum()):
        h = h[1:]
    while h and h[0].isdigit():
        h = h[1:]
    h = h.strip()
    # replace non-alnum with underscore
    out = [ch if ch.isalnum() else '_' for ch in h]
    s = ''.join(out).strip('_')
    return s or 'col'

with open(CSV_PATH, 'r', encoding='utf-8', newline='') as f:
    reader = csv.DictReader(f)
    rows = list(reader)
    orig_headers = reader.fieldnames

new_headers = []
seen = set()
for h in orig_headers:
    nh = clean_name(h)
    base = nh
    i = 1
    while nh in seen:
        i += 1
        nh = f"{base}_{i}"
    seen.add(nh)
    new_headers.append(nh)

with open(CSV_PATH, 'w', encoding='utf-8', newline='') as f:
    writer = csv.DictWriter(f, fieldnames=new_headers)
    writer.writeheader()
    for r in rows:
        new_r = { new_h: r.get(orig_h, '') for orig_h, new_h in zip(orig_headers, new_headers) }
        writer.writerow(new_r)

print("Headers cleaned. Original backed up to", BACKUP_PATH)
print("Mapping:")
for o, n in zip(orig_headers, new_headers):
    print(f"  '{o}' -> '{n}'")

for path in (CSV_PATH, BACKUP_PATH):
    try:
        with open(path, 'r', encoding='utf-8') as f:
            first = f.readline().strip()
    except FileNotFoundError:
        first = '<MISSING>'
    print(f"{path} -> {first}")

new_row = {
    'date': "08-08-2025",
    'open': "197.50",
    'high': "198.40",
    'low': "195.20",
    'close': "197.10",
    'volume': "20000000"
}

with open(CSV_PATH, 'r', encoding='utf-8', newline='') as f:
    fieldnames = csv.DictReader(f).fieldnames

with open(CSV_PATH, 'a', newline='', encoding='utf-8') as file:
    writer = csv.DictWriter(file, fieldnames=fieldnames)
    writer.writerow(new_row)

print("Row appended successfully.")

with open(CSV_PATH, 'r', encoding='utf-8', newline='') as file:
    reader = csv.DictReader(file)
    rows = list(reader)

updated = False
for row in rows:
    if row['date'] == "08-08-2025":
        row['close'] = "198.00"
        updated = True

if updated:
    with open(CSV_PATH, 'w', newline='', encoding='utf-8') as file:
        writer = csv.DictWriter(file, fieldnames=rows[0].keys())
        writer.writeheader()
        writer.writerows(rows)
    print("Row updated successfully.")
else:
    print("No matching date found to update.")

with open(CSV_PATH, 'r', encoding='utf-8') as file:
    reader = csv.reader(file)
    next(reader)  # skip header
    row_count = sum(1 for _ in reader)
print(f"Total rows in file: {row_count}")

with open(CSV_PATH, 'r', encoding='utf-8', newline='') as file:
    reader = csv.DictReader(file)
    data = list(reader)

max_row = max(data, key=lambda x: float(x['close']))
print(f"Max Closing Price: {max_row['close']} on {max_row['date']}")

min_row = min(data, key=lambda x: float(x['close']))
print(f"Min Closing Price: {min_row['close']} on {min_row['date']}")

closing_prices = [float(row['close']) for row in data]
average_close = sum(closing_prices) / len(closing_prices)
print(f"Average Closing Price: {average_close:.2f}")

total_volume = sum(int(float(row['volume'])) for row in data)
print(f"Total Trading Volume: {total_volume:,}")

sorted_rows = sorted(data, key=lambda x: float(x['close']), reverse=True)
top_5 = sorted_rows[:5]

print("Top 5 Highest Closing Prices:")
for row in top_5:
    print(row)

with open('top_5_closing.csv', 'w', newline='', encoding='utf-8') as file:
    writer = csv.DictWriter(file, fieldnames=sorted_rows[0].keys())
    writer.writeheader()
    writer.writerows(top_5)

print("Top 5 closing prices saved to 'top_5_closing.csv'")

filtered_rows = [row for row in data if float(row['close']) > 200]

with open('filtered_closing_above_200.csv', 'w', newline='', encoding='utf-8') as file:
    writer = csv.DictWriter(file, fieldnames=data[0].keys())
    writer.writeheader()
    writer.writerows(filtered_rows)

print(f"Filtered CSV created with {len(filtered_rows)} rows.")

